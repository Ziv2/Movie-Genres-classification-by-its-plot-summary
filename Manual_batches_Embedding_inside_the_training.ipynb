{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ZivSobolModel.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "ce43743b15544c0da2899dc824fcc196": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_f4ebc61f1c09420e90a7a1e40db41406",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_3ceecd4272d542dcb6a8c9bac87a1910",
       "IPY_MODEL_8ed401fb19554e86a70f54a9736cbc90",
       "IPY_MODEL_82c0965048c54e1fb138eef0d4f83722"
      ]
     }
    },
    "f4ebc61f1c09420e90a7a1e40db41406": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "3ceecd4272d542dcb6a8c9bac87a1910": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_4e1c74a5ea1c4d77b881764ebbd69cc7",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Downloading: 100%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_229cf9d35b2b408aab40006ba505bde4"
     }
    },
    "8ed401fb19554e86a70f54a9736cbc90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_957a5f4381664aefbfd062254e143b13",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 391,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 391,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_e50cf74829834dcabb762b40ab3a0974"
     }
    },
    "82c0965048c54e1fb138eef0d4f83722": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d87dca975451418699ec56547d0a2c0e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 391/391 [00:00&lt;00:00, 7.61kB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_27f0dff7e3bc4883ac47db22e920d8c4"
     }
    },
    "4e1c74a5ea1c4d77b881764ebbd69cc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "229cf9d35b2b408aab40006ba505bde4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "957a5f4381664aefbfd062254e143b13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "e50cf74829834dcabb762b40ab3a0974": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "d87dca975451418699ec56547d0a2c0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "27f0dff7e3bc4883ac47db22e920d8c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHmMom-3Y85U"
   },
   "source": [
    "# Genre classification by plot summary\n",
    "The corpus contains descriptions of 30,000 films with high veriability. \n",
    "I assume that it has a high complexity and hidden semantics.\n",
    "For instance, the word \"death\" can be at drama, horror, action, fight, and even comedy. \n",
    "\n",
    "Therefor, I choose to mimic semantic with **transformers**, and not just words counting/distributions/LDA.\n",
    "\n",
    "Because this is an asymmetric semantic task, I used MSMARCO Models. \n",
    "\n",
    "Models trained with a causal language modeling (CLM) objective are better than BERT. \n",
    "\n",
    "# Model input: \n",
    "Embbedings vector for each plot (674 features). \n",
    "\n",
    "Few options: 1. Extract Sementic will be at the start and at the end of each plot. 2. slicing according to the model capacity, and feeding it separately. 3. slice + mix the vectorized representation. \n",
    "\n",
    "\n",
    "# Model output:\n",
    "**Vector of logits to describe each class probability, per plot summary.**\n",
    "This will give a feature representation, *instead* of one vs all. This is because different combinations of classes hide a different semantic. \n",
    "\n",
    "**Labels:** One hot encoding. (vector with size of: n_of_classes)\n",
    "\n",
    "#imbalanced data\n",
    "This data set is multy labeled and imbalanced. \n",
    "\n",
    "Adjustments relative to the imbalanced data need to be considered. {such as Random Undersampling (Tomek Link), Oversampling (SMOTE), Class weights in the models, Change Evaluation Metric and so on.}\n",
    "\n",
    "#validation\n",
    "For quantifing the performance, I need to find the best threshold (relative to accuracy) and fine tune it with validation set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6orxHB7mjybk",
    "outputId": "452916c7-bdd4-4a4a-9a6c-18fc18d25f19"
   },
   "source": [
    "pip install -U sentence-transformers"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "\u001B[K     |████████████████████████████████| 78 kB 3.1 MB/s \n",
      "\u001B[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 2.9 MB 9.5 MB/s \n",
      "\u001B[?25hCollecting tokenizers>=0.10.3\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 43.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.0+cu111)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.2 MB 51.2 MB/s \n",
      "\u001B[?25hCollecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "\u001B[K     |████████████████████████████████| 56 kB 4.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2019.12.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001B[K     |████████████████████████████████| 895 kB 45.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001B[K     |████████████████████████████████| 636 kB 59.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (7.1.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=1f8112ff9de2af238da99a295fb65c66ae0c30411226a7369a0317d95bb45c91\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.19 pyyaml-5.4.1 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.11.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RstiCXLNZCG0"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VO6HFqeLZxC0",
    "outputId": "3d42a292-4c96-46e1-efdf-49400bdcc98c"
   },
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401,
     "referenced_widgets": [
      "ce43743b15544c0da2899dc824fcc196",
      "f4ebc61f1c09420e90a7a1e40db41406",
      "3ceecd4272d542dcb6a8c9bac87a1910",
      "8ed401fb19554e86a70f54a9736cbc90",
      "82c0965048c54e1fb138eef0d4f83722",
      "4e1c74a5ea1c4d77b881764ebbd69cc7",
      "229cf9d35b2b408aab40006ba505bde4",
      "957a5f4381664aefbfd062254e143b13",
      "e50cf74829834dcabb762b40ab3a0974",
      "d87dca975451418699ec56547d0a2c0e",
      "27f0dff7e3bc4883ac47db22e920d8c4",
      "af091a3341b545adb1ceb17184fbbd41"
     ]
    },
    "id": "fJ9WB1ABZT1r",
    "outputId": "58756ce6-62d5-487f-98e9-a8148ed8290f"
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/msmarco-distilroberta-base-v2')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce43743b15544c0da2899dc824fcc196",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780b0257cfa0427486f7ec22f64e5b5c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c393ba324ff4f3bafa0f5d8f412e4bb",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169d05ff9bc14fe5ade6f679a8b02fac",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c47b6a115540fc85eb3d0b16997d2c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e6cd4e3fac4c389887d910503e9d3d",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaffb5e9969d4802a954ad196e5aef0c",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93182d53fd94f298c0f8061c7477fb8",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37fbf3c03664282ad26141c8890a785",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0c5e83e69f4ee0980c53aa20b79133",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c831fb20b7f6462da488135364ef6b01",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca0f72e2f444f03ac673097f7b6ae78",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae989877359473fb326e65c7885c067",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "tGTEtzEIZHKs",
    "outputId": "5f10d719-a8ba-49ca-f28d-5d9dc8380f7c"
   },
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-89b22262-1dfb-4451-bc26-cf7aa3d432e5\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-89b22262-1dfb-4451-bc26-cf7aa3d432e5\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving 100P.csv to 100P.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QJzieqKldcmW"
   },
   "source": [
    "df = pd.read_csv(\"100P.csv\", header=None)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JE5GDOMyVgEG"
   },
   "source": [
    "# train-evaluation split: \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.1)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iz9A1_TgZ2H8"
   },
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.out1 = (self.input_size + self.output_size)//2\n",
    "        self.fc1 = torch.nn.Linear(in_features=self.input_size, out_features=self.out1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.bn = nn.BatchNorm1d(self.out1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(in_features=self.out1, out_features=self.output_size)\n",
    "        self.act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, instance, label):\n",
    "        embeddings = model.encode(instance)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eep5G_tzmQ-n"
   },
   "source": [
    "embeddings_init = [model.encode(df.iloc[0][0])]\n",
    "\n",
    "input_size = len(embeddings_init[0])\n",
    "output_size = train_df.iloc[0, 1:].shape[0]\n",
    "net = Net(input_size=input_size, output_size=output_size).to(device)\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am6lSaqZ6-OV"
   },
   "source": [
    "# I'm using the nn.BCELoss for multiclass-multilabled classification. \n",
    "BCELoss and ***not*** BCEWithLogitsLoss because I want to use the same model for validation/testing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cKKJqe6IaDS0"
   },
   "source": [
    "criterion = nn.BCELoss(reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i827Wd36i8gw"
   },
   "source": [
    "# Creating batchs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uis1_foIaR9M"
   },
   "source": [
    "# Training and Evaluation\n",
    "Due to time constraints, I only tried to catch the overfiting point.\n",
    "\n",
    "Unfortunately I did not had time to add:\n",
    "- Data loader\n",
    "- Creating Batches\n",
    "- Randomization\n",
    "- Revaluation of the Validation_LOSS with Batch and not just single item\n",
    "- BN\n",
    "- Evaluation matrix "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QNo7dBkTld3e"
   },
   "source": [
    "    # eval_embeddings = [model.encode(eval_df.iloc[i][0]) for i in range(eval_df.shape[0])]\n",
    "\n",
    "    # input_size = len(embeddings[0])\n",
    "    # output_size = train_df.iloc[0, 1:].shape[0]\n",
    "    # net = Net(input_size=input_size, output_size=output_size).to(device)\n"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "e-0urP3K0AOS"
   },
   "source": [
    "# idx_val_batch = np.random.choice(list(range(eval_df.shape[0])), size = 10)\n",
    "# val_b_embeddings = [model.encode(val_df.iloc[i][0]) for i in idx_val_batch]\n",
    "# val_b_embeddings = torch.tensor(val_b_embeddings)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wsQVU4apqQG-"
   },
   "source": [
    "# train_b_embed = model.encode(train_df.iloc[1][0])\n"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4uBtgiKKyn-H",
    "outputId": "a88fac4d-f63c-4c6b-bf96-22fa4cf75237"
   },
   "source": [
    "train_df.shape[0]"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "zWPsR_BNmMDz",
    "outputId": "5b60af7b-e4d7-4ba6-bfaf-1d0f0d012b83"
   },
   "source": [
    "epochs=10\n",
    "batch_size = 5 \n",
    "for epoch in range(epochs):\n",
    "    train_df.sample(frac=1)\n",
    "    val_df.sample(frac=1)\n",
    "    loss = torch.tensor(0.)\n",
    "    \n",
    "    for i in range(0, train_df.shape[0], batch_size):\n",
    "        # print(\"i is: \", i)\n",
    "        train_batch = train_df.iloc[i:i+batch_size]\n",
    "        loss = torch.FloatTensor([0])\n",
    "        for j in range(train_batch.shape[0]):\n",
    "            train_embed = torch.tensor(model.encode(train_batch.iloc[j][0]))\n",
    "            l = train_batch.iloc[j, 1:].values\n",
    "            labels = torch.tensor(l.astype(float)).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(train_embed.to(device))\n",
    "            labels = labels.float()\n",
    "            outputs = outputs.float()\n",
    "            loss = loss + criterion(outputs.unsqueeze(-1), labels.unsqueeze(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch%3==0:\n",
    "        val_loss = torch.tensor(0.)\n",
    "        for k in range(0, val_df.shape[0], batch_size):\n",
    "            val_batch = val_df.iloc[k:k+batch_size]\n",
    "            loss = torch.FloatTensor([0])\n",
    "            for m in range(val_batch.shape[0]):\n",
    "                val_embed = torch.tensor(model.encode(val_batch.iloc[j][0]))\n",
    "                val_l = val_batch.iloc[m, 1:].values\n",
    "                val_labels = torch.tensor(val_l.astype(float)).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                val_outputs = net(val_embed.to(device))\n",
    "                val_labels = labels.float()\n",
    "                val_outputs = val_outputs.float()\n",
    "                val_loss += criterion(val_outputs.unsqueeze(-1), val_labels.unsqueeze(-1))\n",
    "  \n",
    "        torch.save(net.state_dict(), \"model_weights_\"+str(epoch))\n",
    "        torch.save(model.state_dict(), 'checkpoint.pth'+str(epoch))\n",
    "        files.download('checkpoint_'+str(epoch)+'.pth')\n",
    "\n",
    "        print('Epoch [%d/%d], Iter [%d]:' %(epoch+1, epochs, i+1))\n",
    "        print('                        Train loss: %.4f' % (loss))\n",
    "        print('                        Evaluation loss: %.4f' % (val_loss))\n",
    "\n"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-45-e8ae5654672d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"model_weights_\"\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'checkpoint.pth'\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0mfiles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'checkpoint_'\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m'.pth'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Epoch [%d/%d], Iter [%d]:'\u001B[0m \u001B[0;34m%\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(filename)\u001B[0m\n\u001B[1;32m    141\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m       \u001B[0;32mraise\u001B[0m \u001B[0mFileNotFoundError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=undefined-variable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m   \u001B[0mcomm_manager\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_IPython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkernel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcomm_manager\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Cannot find file: checkpoint_0.pth"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nJGZ_es7lnap"
   },
   "source": [
    "# torch.save(net.state_dict(), \"model_weights.pth\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B62lv3lVSdwm"
   },
   "source": [
    "# Creating an inference class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z8JPDXJGAncF"
   },
   "source": [
    "# I created a dictionary for the Genres names at the preprocessing notebook. \n",
    "# lis = [df2.keys()[i] for i in range(df2.shape[1])]\n",
    "# for i, gen in enumerate (lis):\n",
    "#     print (i,':\"',gen,'\",')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RTzPaiod_au_"
   },
   "source": [
    "genre_dict = {0 :\" Absurdism \",\n",
    "1 :\" Acid western \",\n",
    "2 :\" Action \",\n",
    "3 :\" Action Comedy \",\n",
    "4 :\" Action Thrillers \",\n",
    "5 :\" Action/Adventure \",\n",
    "6 :\" Addiction Drama \",\n",
    "7 :\" Adult \",\n",
    "8 :\" Adventure \",\n",
    "9 :\" Adventure Comedy \",\n",
    "10 :\" Airplanes and airports \",\n",
    "11 :\" Albino bias \",\n",
    "12 :\" Alien Film \",\n",
    "13 :\" Alien invasion \",\n",
    "14 :\" Americana \",\n",
    "15 :\" Animal Picture \",\n",
    "16 :\" Animals \",\n",
    "17 :\" Animated Musical \",\n",
    "18 :\" Animated cartoon \",\n",
    "19 :\" Animation \",\n",
    "20 :\" Anime \",\n",
    "21 :\" Anthology \",\n",
    "22 :\" Anthropology \",\n",
    "23 :\" Anti-war \",\n",
    "24 :\" Anti-war film \",\n",
    "25 :\" Apocalyptic and post-apocalyptic fiction \",\n",
    "26 :\" Archaeology \",\n",
    "27 :\" Archives and records \",\n",
    "28 :\" Art film \",\n",
    "29 :\" Auto racing \",\n",
    "30 :\" Avant-garde \",\n",
    "31 :\" B-Western \",\n",
    "32 :\" B-movie \",\n",
    "33 :\" Backstage Musical \",\n",
    "34 :\" Baseball \",\n",
    "35 :\" Beach Film \",\n",
    "36 :\" Beach Party film \",\n",
    "37 :\" Bengali Cinema \",\n",
    "38 :\" Biker Film \",\n",
    "39 :\" Biographical film \",\n",
    "40 :\" Biography \",\n",
    "41 :\" Biopic [feature] \",\n",
    "42 :\" Black comedy \",\n",
    "43 :\" Black-and-white \",\n",
    "44 :\" Blaxploitation \",\n",
    "45 :\" Bloopers & Candid Camera \",\n",
    "46 :\" Bollywood \",\n",
    "47 :\" Boxing \",\n",
    "48 :\" Breakdance \",\n",
    "49 :\" British Empire Film \",\n",
    "50 :\" British New Wave \",\n",
    "51 :\" Bruceploitation \",\n",
    "52 :\" Buddy Picture \",\n",
    "53 :\" Buddy cop \",\n",
    "54 :\" Buddy film \",\n",
    "55 :\" Business \",\n",
    "56 :\" Camp \",\n",
    "57 :\" Caper story \",\n",
    "58 :\" Cavalry Film \",\n",
    "59 :\" Chase Movie \",\n",
    "60 :\" Chick flick \",\n",
    "61 :\" Childhood Drama \",\n",
    "62 :\" Children's \",\n",
    "63 :\" Children's Entertainment \",\n",
    "64 :\" Children's Fantasy \",\n",
    "65 :\" Children's/Family \",\n",
    "66 :\" Chinese Movies \",\n",
    "67 :\" Christian film \",\n",
    "68 :\" Christmas movie \",\n",
    "69 :\" Clay animation \",\n",
    "70 :\" Cold War \",\n",
    "71 :\" Combat Films \",\n",
    "72 :\" Comdedy \",\n",
    "73 :\" Comedy \",\n",
    "74 :\" Comedy Thriller \",\n",
    "75 :\" Comedy Western \",\n",
    "76 :\" Comedy film \",\n",
    "77 :\" Comedy horror \",\n",
    "78 :\" Comedy of Errors \",\n",
    "79 :\" Comedy of manners \",\n",
    "80 :\" Comedy-drama \",\n",
    "81 :\" Coming of age \",\n",
    "82 :\" Coming-of-age film \",\n",
    "83 :\" Computer Animation \",\n",
    "84 :\" Computers \",\n",
    "85 :\" Concert film \",\n",
    "86 :\" Conspiracy fiction \",\n",
    "87 :\" Costume Adventure \",\n",
    "88 :\" Costume Horror \",\n",
    "89 :\" Costume drama \",\n",
    "90 :\" Courtroom Comedy \",\n",
    "91 :\" Courtroom Drama \",\n",
    "92 :\" Creature Film \",\n",
    "93 :\" Crime \",\n",
    "94 :\" Crime Comedy \",\n",
    "95 :\" Crime Drama \",\n",
    "96 :\" Crime Fiction \",\n",
    "97 :\" Crime Thriller \",\n",
    "98 :\" Cult \",\n",
    "99 :\" Culture & Society \",\n",
    "100 :\" Cyberpunk \",\n",
    "101 :\" Czechoslovak New Wave \",\n",
    "102 :\" Dance \",\n",
    "103 :\" Demonic child \",\n",
    "104 :\" Detective \",\n",
    "105 :\" Detective fiction \",\n",
    "106 :\" Disaster \",\n",
    "107 :\" Docudrama \",\n",
    "108 :\" Documentary \",\n",
    "109 :\" Dogme 95 \",\n",
    "110 :\" Domestic Comedy \",\n",
    "111 :\" Doomsday film \",\n",
    "112 :\" Drama \",\n",
    "113 :\" Dystopia \",\n",
    "114 :\" Ealing Comedies \",\n",
    "115 :\" Early Black Cinema \",\n",
    "116 :\" Education \",\n",
    "117 :\" Educational \",\n",
    "118 :\" Ensemble Film \",\n",
    "119 :\" Environmental Science \",\n",
    "120 :\" Epic \",\n",
    "121 :\" Epic Western \",\n",
    "122 :\" Erotic Drama \",\n",
    "123 :\" Erotic thriller \",\n",
    "124 :\" Erotica \",\n",
    "125 :\" Escape Film \",\n",
    "126 :\" Essay Film \",\n",
    "127 :\" Existentialism \",\n",
    "128 :\" Experimental film \",\n",
    "129 :\" Exploitation \",\n",
    "130 :\" Expressionism \",\n",
    "131 :\" Extreme Sports \",\n",
    "132 :\" Fairy tale \",\n",
    "133 :\" Family & Personal Relationships \",\n",
    "134 :\" Family Drama \",\n",
    "135 :\" Family Film \",\n",
    "136 :\" Family-Oriented Adventure \",\n",
    "137 :\" Fan film \",\n",
    "138 :\" Fantasy \",\n",
    "139 :\" Fantasy Adventure \",\n",
    "140 :\" Fantasy Comedy \",\n",
    "141 :\" Fantasy Drama \",\n",
    "142 :\" Feature film \",\n",
    "143 :\" Female buddy film \",\n",
    "144 :\" Feminist Film \",\n",
    "145 :\" Fictional film \",\n",
    "146 :\" Filipino \",\n",
    "147 :\" Filipino Movies \",\n",
    "148 :\" Film \",\n",
    "149 :\" Film & Television History \",\n",
    "150 :\" Film adaptation \",\n",
    "151 :\" Film noir \",\n",
    "152 :\" Film à clef \",\n",
    "153 :\" Film-Opera \",\n",
    "154 :\" Filmed Play \",\n",
    "155 :\" Finance & Investing \",\n",
    "156 :\" Foreign legion \",\n",
    "157 :\" Future noir \",\n",
    "158 :\" Gangster Film \",\n",
    "159 :\" Gay \",\n",
    "160 :\" Gay Interest \",\n",
    "161 :\" Gay Themed \",\n",
    "162 :\" Gay pornography \",\n",
    "163 :\" Gender Issues \",\n",
    "164 :\" Giallo \",\n",
    "165 :\" Glamorized Spy Film \",\n",
    "166 :\" Goat gland \",\n",
    "167 :\" Gothic Film \",\n",
    "168 :\" Graphic & Applied Arts \",\n",
    "169 :\" Gross out \",\n",
    "170 :\" Gross-out film \",\n",
    "171 :\" Gulf War \",\n",
    "172 :\" Hagiography \",\n",
    "173 :\" Hardcore pornography \",\n",
    "174 :\" Haunted House Film \",\n",
    "175 :\" Health & Fitness \",\n",
    "176 :\" Heaven-Can-Wait Fantasies \",\n",
    "177 :\" Heavenly Comedy \",\n",
    "178 :\" Heist \",\n",
    "179 :\" Hip hop movies \",\n",
    "180 :\" Historical Documentaries \",\n",
    "181 :\" Historical Epic \",\n",
    "182 :\" Historical drama \",\n",
    "183 :\" Historical fiction \",\n",
    "184 :\" History \",\n",
    "185 :\" Holiday Film \",\n",
    "186 :\" Horror \",\n",
    "187 :\" Horror Comedy \",\n",
    "188 :\" Horse racing \",\n",
    "189 :\" Humour \",\n",
    "190 :\" Hybrid Western \",\n",
    "191 :\" Illnesses & Disabilities \",\n",
    "192 :\" Indian Western \",\n",
    "193 :\" Indie \",\n",
    "194 :\" Inspirational Drama \",\n",
    "195 :\" Instrumental Music \",\n",
    "196 :\" Interpersonal Relationships \",\n",
    "197 :\" Inventions & Innovations \",\n",
    "198 :\" Japanese Movies \",\n",
    "199 :\" Journalism \",\n",
    "200 :\" Jukebox musical \",\n",
    "201 :\" Jungle Film \",\n",
    "202 :\" Juvenile Delinquency Film \",\n",
    "203 :\" Kafkaesque \",\n",
    "204 :\" Kitchen sink realism \",\n",
    "205 :\" LGBT \",\n",
    "206 :\" Language & Literature \",\n",
    "207 :\" Latino \",\n",
    "208 :\" Law & Crime \",\n",
    "209 :\" Legal drama \",\n",
    "210 :\" Libraries and librarians \",\n",
    "211 :\" Linguistics \",\n",
    "212 :\" Live action \",\n",
    "213 :\" Malayalam Cinema \",\n",
    "214 :\" Marriage Drama \",\n",
    "215 :\" Martial Arts Film \",\n",
    "216 :\" Master Criminal Films \",\n",
    "217 :\" Media Satire \",\n",
    "218 :\" Media Studies \",\n",
    "219 :\" Medical fiction \",\n",
    "220 :\" Melodrama \",\n",
    "221 :\" Mockumentary \",\n",
    "222 :\" Mondo film \",\n",
    "223 :\" Monster \",\n",
    "224 :\" Monster movie \",\n",
    "225 :\" Movie serial \",\n",
    "226 :\" Movies About Gladiators \",\n",
    "227 :\" Mumblecore \",\n",
    "228 :\" Music \",\n",
    "229 :\" Musical \",\n",
    "230 :\" Musical Drama \",\n",
    "231 :\" Musical comedy \",\n",
    "232 :\" Mystery \",\n",
    "233 :\" Mythological Fantasy \",\n",
    "234 :\" Natural disaster \",\n",
    "235 :\" Natural horror films \",\n",
    "236 :\" Nature \",\n",
    "237 :\" Neo-noir \",\n",
    "238 :\" Neorealism \",\n",
    "239 :\" New Hollywood \",\n",
    "240 :\" News \",\n",
    "241 :\" Ninja movie \",\n",
    "242 :\" Northern \",\n",
    "243 :\" Operetta \",\n",
    "244 :\" Outlaw \",\n",
    "245 :\" Outlaw biker film \",\n",
    "246 :\" Parkour in popular culture \",\n",
    "247 :\" Parody \",\n",
    "248 :\" Patriotic film \",\n",
    "249 :\" Period piece \",\n",
    "250 :\" Pinku eiga \",\n",
    "251 :\" Plague \",\n",
    "252 :\" Point of view shot \",\n",
    "253 :\" Political Documetary \",\n",
    "254 :\" Political cinema \",\n",
    "255 :\" Political drama \",\n",
    "256 :\" Political satire \",\n",
    "257 :\" Political thriller \",\n",
    "258 :\" Pornographic movie \",\n",
    "259 :\" Pornography \",\n",
    "260 :\" Pre-Code \",\n",
    "261 :\" Prison \",\n",
    "262 :\" Prison escape \",\n",
    "263 :\" Prison film \",\n",
    "264 :\" Private military company \",\n",
    "265 :\" Propaganda film \",\n",
    "266 :\" Psycho-biddy \",\n",
    "267 :\" Psychological horror \",\n",
    "268 :\" Psychological thriller \",\n",
    "269 :\" Punk rock \",\n",
    "270 :\" Race movie \",\n",
    "271 :\" Reboot \",\n",
    "272 :\" Religious Film \",\n",
    "273 :\" Remake \",\n",
    "274 :\" Revenge \",\n",
    "275 :\" Revisionist Fairy Tale \",\n",
    "276 :\" Revisionist Western \",\n",
    "277 :\" Road movie \",\n",
    "278 :\" Road-Horror \",\n",
    "279 :\" Roadshow theatrical release \",\n",
    "280 :\" Roadshow/Carny \",\n",
    "281 :\" Rockumentary \",\n",
    "282 :\" Romance Film \",\n",
    "283 :\" Romantic comedy \",\n",
    "284 :\" Romantic drama \",\n",
    "285 :\" Romantic fantasy \",\n",
    "286 :\" Romantic thriller \",\n",
    "287 :\" Samurai cinema \",\n",
    "288 :\" Satire \",\n",
    "289 :\" School story \",\n",
    "290 :\" Sci Fi Pictures original films \",\n",
    "291 :\" Sci-Fi Adventure \",\n",
    "292 :\" Sci-Fi Horror \",\n",
    "293 :\" Sci-Fi Thriller \",\n",
    "294 :\" Science Fiction \",\n",
    "295 :\" Science fiction Western \",\n",
    "296 :\" Screwball comedy \",\n",
    "297 :\" Sex comedy \",\n",
    "298 :\" Sexploitation \",\n",
    "299 :\" Short Film \",\n",
    "300 :\" Silent film \",\n",
    "301 :\" Silhouette animation \",\n",
    "302 :\" Singing cowboy \",\n",
    "303 :\" Slapstick \",\n",
    "304 :\" Slasher \",\n",
    "305 :\" Slice of life story \",\n",
    "306 :\" Social issues \",\n",
    "307 :\" Social problem film \",\n",
    "308 :\" Softcore Porn \",\n",
    "309 :\" Space opera \",\n",
    "310 :\" Space western \",\n",
    "311 :\" Spaghetti Western \",\n",
    "312 :\" Splatter film \",\n",
    "313 :\" Sponsored film \",\n",
    "314 :\" Sports \",\n",
    "315 :\" Spy \",\n",
    "316 :\" Stand-up comedy \",\n",
    "317 :\" Star vehicle \",\n",
    "318 :\" Statutory rape \",\n",
    "319 :\" Steampunk \",\n",
    "320 :\" Stoner film \",\n",
    "321 :\" Stop motion \",\n",
    "322 :\" Superhero \",\n",
    "323 :\" Superhero movie \",\n",
    "324 :\" Supermarionation \",\n",
    "325 :\" Supernatural \",\n",
    "326 :\" Surrealism \",\n",
    "327 :\" Suspense \",\n",
    "328 :\" Swashbuckler films \",\n",
    "329 :\" Sword and Sandal \",\n",
    "330 :\" Sword and sorcery \",\n",
    "331 :\" Sword and sorcery films \",\n",
    "332 :\" Tamil cinema \",\n",
    "333 :\" Teen \",\n",
    "334 :\" Television movie \",\n",
    "335 :\" The Netherlands in World War II \",\n",
    "336 :\" Therimin music \",\n",
    "337 :\" Thriller \",\n",
    "338 :\" Time travel \",\n",
    "339 :\" Tokusatsu \",\n",
    "340 :\" Tollywood \",\n",
    "341 :\" Tragedy \",\n",
    "342 :\" Tragicomedy \",\n",
    "343 :\" Travel \",\n",
    "344 :\" Vampire movies \",\n",
    "345 :\" War film \",\n",
    "346 :\" Werewolf fiction \",\n",
    "347 :\" Western \",\n",
    "348 :\" Whodunit \",\n",
    "349 :\" Women in prison films \",\n",
    "350 :\" Workplace Comedy \",\n",
    "351 :\" World History \",\n",
    "352 :\" World cinema \",\n",
    "353 :\" Wuxia \",\n",
    "354 :\" Z movie \",\n",
    "355 :\" Zombie Film \"}"
   ],
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bF5M7ydCSiJH"
   },
   "source": [
    "class Test():\n",
    "    def __init__(self, plot):\n",
    "        self.plot = plot\n",
    "\n",
    "    def inference(self):\n",
    "\n",
    "        embedTest = model.encode(self.plot)\n",
    "        embedTest = torch.tensor(embedTest)\n",
    "        net_pred = Net(input_size=768, output_size=356).to(device)\n",
    "        net_pred.load_state_dict(torch.load('/content/model_weights.pth', map_location='cpu'))\n",
    "        net_pred.eval()\n",
    "        outputs = net_pred(embedTest.to(device))\n",
    "        out ={}\n",
    "        for i, prob in enumerate(outputs):\n",
    "            if prob>0.1:\n",
    "                prob =prob*100\n",
    "                # print('Genre' ,genre_dict[i], 'prob [%.2f]:' %(prob))\n",
    "                print(genre_dict[i], \"(%.0f\" %(prob), \"%)\")\n",
    "                # out[i] = prob\n",
    "                # print('Epoch [%d/%d], Iter [%d]:' %(epoch+1, epochs, i+1))\n",
    "        # return out"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9p5dPtmfkRQr"
   },
   "source": [
    "plot= \"The film begins in Kuvukiland, an undeveloped kingdom somewhere in Africa. Mr. Bones arrives as a baby, the sole survivor of an airplane crash that happens nearby. He grows older and becomes the bone-throwing prophesier for the kingdom. King Tsonga, ruler of Kuvukiland, longs for a male child to be heir to the throne. After having seventeen children, all of them girls, he gives up hope, until he remembers fathering a boy decades before in Sun City. He immediately sends Mr. Bones to find the future prince. At the same time golf star Vince \\\"The Prince\\\" Lee, along with his coach, The Wild Bull, arrives in Sun City for a golf tournament. A local casino owner places a huge bet on Vince Lee winning the tournament, but just before it begins, Wild Bull is injured in a freak accident. He quickly recovers, but is held against his will in a local hospital. Without his coach, Vince Lee plays terribly, until he meets the eccentric Mr. Bones, who believes him to be the actual prince, and gives him a lucky streak. Vince nearly wins the game until Mr. Bones remembers his mission and stops a perfect putt. Vince retires in disgrace, but meets a local singer, Laleti, afterwards, whom he is stricken with. Mr. Bones notices this, and by impersonating her, he kidnaps Vince. The next day, Wild Bull manages to escape from the hospital and goes on a search for Vince, along with Laleti and her mother. Enraged by Vince Lee's performance, and by the fact that everyone had gone missing, the casino owner mounts a search for them in a helicopter, along with two of his henchmen. After a series of comical mishaps, they all meet near Kuvukiland. Mr. Bones introduces Vince to King Tsonga, but after discovering that Vince is terrified of animals, King Tsonga disowns him, and prepares to die. The casino owner quickly locates Vince and Laleti, and attempts to kill them both, but Vince escapes. He finds Laleti tied to a tree with a lion about to eat her, and overcoming his fear, he chases the lion away. King Tsonga sees this, and decides that he doesn't want to die. Soon after, the casino owner reappears, but Mr. Bones, with the help of an elephant, causes the helicopter to crash. King Tsonga proclaims that Vince is his son, but askes Mr. Bones to throw his prophesy bones once more just to be sure. As Mr. Bones does this, Wild Bull arrives upon the scene, and it is confirmed that he is the actual prince. The film closes with Mr. Bones, King Tsonga, and Wild Bull watching from Kuvukiland as Vince Lee, now married to Laleti, wins the US Open golf tournament.\\n\"\n",
    "\n",
    "test = Test(plot)\n",
    "test.inference()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WCEC7gbpiC7H"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/model_weights')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, plot):\n",
    "        self.plot = plot\n",
    "\n",
    "    def inference(self):\n",
    "\n",
    "        embedTest = model.encode(self.plot)\n",
    "        embedTest = torch.tensor(embedTest)\n",
    "        net_pred = Net(input_size=768, output_size=356).to(device)\n",
    "        net_pred.load_state_dict(torch.load('/content/model_weights.pth', map_location='cpu'))\n",
    "        net_pred.eval()\n",
    "        outputs = net_pred(embedTest.to(device))\n",
    "        out ={}\n",
    "        for i, prob in enumerate(outputs):\n",
    "            if prob>0.1:\n",
    "                prob =prob*100\n",
    "                # print('Genre' ,genre_dict[i], 'prob [%.2f]:' %(prob))\n",
    "                print(genre_dict[i], \"(%.0f\" %(prob), \"%)\")\n",
    "                # out[i] = prob\n",
    "                # print('Epoch [%d/%d], Iter [%d]:' %(epoch+1, epochs, i+1))\n",
    "        # return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}